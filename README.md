**Project Overview**
--

The purpose of developing an abstractive text summarizer is to automatically generate concise and coherent summaries of longer texts while preserving the main ideas and key information. 
Abstractive summarization is a task typically associated with natural language processing (NLP).

Model Used:
--

•	BART-Large is a variant of the BART (Bidirectional and Auto-Regressive Transformers) model, which is a powerful language generation model. BART-Large is specifically trained on a large-scale dataset and has a larger model size compared to the base BART model.

•	With increased capacity and parameters, BART-Large demonstrates enhanced performance in various natural language processing tasks such as text summarization, translation, and text generation. The larger size of BART-Large allows it to capture more intricate language patterns, leading to improved language understanding and generation capabilities.

A brief look at the project:
--

![Screenshot 2023-11-28 220340](https://github.com/Yashhuc/Text-Summarizer/assets/120786462/b8435385-607c-44d7-a3da-4e0a3dbbfc55)
![Screenshot 2023-11-28 220522](https://github.com/Yashhuc/Text-Summarizer/assets/120786462/7b4f8364-1d9a-4505-83b8-8d9aa3460ba1)
![Screenshot 2023-11-28 221025](https://github.com/Yashhuc/Text-Summarizer/assets/120786462/6b227c42-d96e-4ca0-b207-d5767f6be5d5)



