**Project Overview**
--

The purpose of developing an abstractive text summarizer is to automatically generate concise and coherent summaries of longer texts while preserving the main ideas and key information. 
Abstractive summarization is a task typically associated with natural language processing (NLP).

Model Used:
--

•	BART-Large is a variant of the BART (Bidirectional and Auto-Regressive Transformers) model, which is a powerful language generation model. BART-Large is specifically trained on a large-scale dataset and has a larger model size compared to the base BART model.

•	With increased capacity and parameters, BART-Large demonstrates enhanced performance in various natural language processing tasks such as text summarization, translation, and text generation. The larger size of BART-Large allows it to capture more intricate language patterns, leading to improved language understanding and generation capabilities.

A brief look at the project:
--

![Screenshot 2024-07-14 161816](https://github.com/user-attachments/assets/41e5b288-54a9-4ba6-99e9-dcb2a694b05b)
![Screenshot 2024-07-14 161928](https://github.com/user-attachments/assets/ee60c7b3-f29c-4607-a278-2207a5e1d6de)
![Screenshot 2024-07-14 161944](https://github.com/user-attachments/assets/11d3cd15-2580-45c4-b05e-d18e5ff7054c)
![Screenshot 2024-07-14 162005](https://github.com/user-attachments/assets/dd70c16b-5a5f-4be4-8a2f-ec0a4f72051a)
![Screenshot 2024-07-14 162035](https://github.com/user-attachments/assets/90f39b87-d9ec-43c7-8b25-351966a3aa50)








